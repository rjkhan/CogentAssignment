{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0a922ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Necessary imports\n",
    "# !pip install pymupdf\n",
    "# !pip install openai\n",
    "# !pip install langchain\n",
    "# !pip install tiktoken\n",
    "# !pip install reportlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283fddc4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f06811e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "import tiktoken\n",
    "import os\n",
    "import warnings\n",
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# OpenAI API key Setting\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b7780",
   "metadata": {},
   "source": [
    "## Read and Parse pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea09f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_structure(pdf_content):\n",
    "    \"\"\"\n",
    "    Parses the content of a PDF to create a structured dictionary representing parts, chapters, and their content.\n",
    "\n",
    "    This function takes the text content of a PDF and processes it to create a structured dictionary where parts are\n",
    "    represented as keys, chapters are nested within parts, and their content is stored as values.\n",
    "\n",
    "    Args:\n",
    "        pdf_content (list of str): A list of text content from the PDF where each element represents a page.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the PDF structure with parts, chapters, and content.\n",
    "              The structure is organized as follows:\n",
    "              {\n",
    "                  \"Part 1\": {\n",
    "                      \"Chapter 1\": \"Chapter 1 content...\",\n",
    "                      \"Chapter 2\": \"Chapter 2 content...\",\n",
    "                      ...\n",
    "                  },\n",
    "                  \"Part 2\": {\n",
    "                      \"Chapter 1\": \"Chapter 1 content...\",\n",
    "                      \"Chapter 2\": \"Chapter 2 content...\",\n",
    "                      ...\n",
    "                  },\n",
    "                  ...\n",
    "              }\n",
    "    \"\"\"\n",
    "    pdf_structure = {}\n",
    "    current_part = None\n",
    "    current_chapter = None\n",
    "    current_text = []\n",
    "    \n",
    "    if len(pdf_content):\n",
    "        for page_text in pdf_content:\n",
    "            lines = page_text.strip().split('\\n')\n",
    "            for line in lines:\n",
    "                # Check if the line contains a part number (e.g., \"Part 1\")\n",
    "                if line.startswith(\"Part \"):\n",
    "                    if current_part:\n",
    "                        pdf_structure[current_part][current_chapter] = '\\n'.join(current_text)\n",
    "                    current_part = line.strip()\n",
    "                    current_chapter = None\n",
    "                    current_text = []\n",
    "                    if current_part not in pdf_structure:\n",
    "                        pdf_structure[current_part] = {}\n",
    "\n",
    "                # Check if the line contains a chapter number (e.g., \"Chapter 1\")\n",
    "                elif line.startswith(\"Chapter \"):\n",
    "                    if current_chapter:\n",
    "                        pdf_structure[current_part][current_chapter] = '\\n'.join(current_text)\n",
    "                    current_chapter = line.strip()\n",
    "                    current_text = []\n",
    "                    if current_chapter not in pdf_structure[current_part]:\n",
    "                        pdf_structure[current_part][current_chapter] = []\n",
    "\n",
    "                # If the line is not a part or chapter, assume it's part of the chapter text\n",
    "                elif current_chapter:\n",
    "                    current_text.append(line)\n",
    "\n",
    "        # Add the last part and chapter\n",
    "        if current_part and current_chapter:\n",
    "            chapter_content = '\\n'.join(current_text)\n",
    "            pdf_structure[current_part][current_chapter] = chapter_content\n",
    "            \n",
    "\n",
    "    return pdf_structure\n",
    "\n",
    "\n",
    "def extract_pdf_data(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text content from a PDF file.\n",
    "\n",
    "    This function opens a PDF file located at the specified 'pdf_path' and extracts\n",
    "    the text content from all pages in the PDF. The extracted text content is\n",
    "    returned as a list, where each element represents the text content of a single page.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The file path to the PDF to be extracted.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings, where each string represents the text content of a single page in the PDF.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If there is an error while processing the PDF file.\n",
    "    \"\"\"\n",
    "    pdf_content = []\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            page_text = page.get_text()\n",
    "            pdf_content.append(page_text)\n",
    "\n",
    "        pdf_document.close()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error while extracting PDF data: {str(e)}\")\n",
    "    return pdf_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c312437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pdf content\n",
    "# pdf_path = 'crime-and-punishment.pdf'\n",
    "# pdf_data = extract_pdf_data(pdf_path)\n",
    "# pdf_structure = create_pdf_structure(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58977b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pdf as json\n",
    "# import json\n",
    "# def save_json(data):\n",
    "#     json_string = json.dumps(data)\n",
    "\n",
    "#     # Serialize to a JSON file\n",
    "#     with open(\"book.json\", \"w\") as json_file:\n",
    "#         json.dump(data, json_file)\n",
    "# # save_json(pdf_structure)\n",
    "\n",
    "\n",
    "# def read_json(file_name):\n",
    "#     with open(file_name, \"r\") as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#     return data\n",
    "\n",
    "# # load pdf from json\n",
    "# # pdf_data = read_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9fb47b",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90090c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt():\n",
    "    \"\"\"\n",
    "    Generates a prompt for summarizing a given text.\n",
    "\n",
    "    This function generates a prompt template that instructs the user to write a brief,\n",
    "    concise, coherent, accurate, and relevant summary of a provided text.\n",
    "\n",
    "    Returns:\n",
    "        PromptTemplate: A PromptTemplate instance containing the generated prompt template.\n",
    "    \"\"\"\n",
    "    prompt_template = \"\"\"Write a breif, concise, coherent , accurate and relevance summary of the following:\n",
    "\n",
    "    \"{text}\"\n",
    "    INSTRUCTION: DO not use \"in this passage\"\n",
    "\n",
    "\n",
    "    CONCISE SUMMARY:\"\"\"\n",
    "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "    return PROMPT\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    \"\"\"\n",
    "    Preprocesses a text by removing newline characters and a specific watermark.\n",
    "\n",
    "    This function takes an input text and performs preprocessing by removing newline characters\n",
    "    and a watermark, such as \"Free eBooks at Planet eBook.com,\" from the text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        str: The preprocessed text with newline characters and watermark removed.\n",
    "    \"\"\"\n",
    "    if len(text):\n",
    "        text = text.replace(\"\\n\", '')\n",
    "        text = text.replace(\"Free eBooks at Planet eBook.com\", \"\")\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def chunking_data(text):\n",
    "    \"\"\"\n",
    "    Chunk a long text into smaller segments.\n",
    "\n",
    "    This function takes a long text as input and splits it into smaller segments using\n",
    "    a text splitter (e.g., CharacterTextSplitter). Each segment becomes a separate document.\n",
    "\n",
    "    Args:\n",
    "        text (str): The long text to be segmented.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of segmented text segments.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    if len(text):\n",
    "        text_splitter = CharacterTextSplitter()\n",
    "        docs = text_splitter.split_text(text)\n",
    "    return docs\n",
    "\n",
    "\n",
    "\n",
    "def create_model_object(temperature, model_name, max_token):\n",
    "    \"\"\"\n",
    "    Create an instance of a language model.\n",
    "\n",
    "    This function initializes a language model object with the specified parameters, including temperature,\n",
    "    model name, and maximum token limit.\n",
    "\n",
    "    Args:\n",
    "        temperature (float): The temperature parameter controlling the randomness of the model's responses.\n",
    "        model_name (str): The name or identifier of the language model to be used.\n",
    "        max_token (int): The maximum number of tokens allowed in the model's responses.\n",
    "\n",
    "    Returns:\n",
    "        OpenAI: An instance of the language model with the specified configuration.\n",
    "    \"\"\"\n",
    "    llm = OpenAI(temperature=temperature, model_name=model_name, max_tokens=max_token)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f88ca5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summaries(data):\n",
    "    \"\"\"\n",
    "    Generate summaries for the provided data.\n",
    "\n",
    "    This function processes a dictionary containing text data organized by part and chapter numbers.\n",
    "    It generates summaries for each chapter's text using a language model and returns the summaries\n",
    "    in a dictionary format.\n",
    "\n",
    "    Args:\n",
    "        data (dict): A dictionary containing text data organized by part and chapter numbers.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing summaries for each chapter, organized by part and chapter numbers.\n",
    "    \"\"\"\n",
    "    summary_dict = {}\n",
    "    if len(data):\n",
    "        llm = create_model_object(0.9, \"gpt-3.5-turbo-16k\", 500)\n",
    "        for part_number in data.keys():\n",
    "            summary_dict[part_number] = {}\n",
    "            for chapter_number in data[part_number].keys():\n",
    "                output_summary = \"\"\n",
    "                print(f\"Processing part: {part_number} and chapter number: {chapter_number}\")\n",
    "                try:\n",
    "                    clean_chapter_text = preprocessing(data[part_number][chapter_number])\n",
    "                    docs = chunking_data(clean_chapter_text)\n",
    "                    prompt = generate_prompt()\n",
    "                    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "                    output_summary = chain.run(docs)\n",
    "                    summary_dict[part_number][chapter_number] = output_summary\n",
    "                except:\n",
    "                    summary_dict[part_number][chapter_number] = output_summary\n",
    "                    # output_summary = chain.run(docs[0])\n",
    "\n",
    "    return summary_dict\n",
    "\n",
    "\n",
    "# # pdf chapter wise summaries\n",
    "# pdf_summaries = generate_summaries(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bb392d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_json(data):\n",
    "    \n",
    "    final_book = {}\n",
    "    try:\n",
    "        for part_number in data.keys():\n",
    "            final_book[part_number] = []\n",
    "            for chapter in data[part_number].keys():\n",
    "                final_book[part_number] += [data[part_number][chapter]]\n",
    "    except ValueError:\n",
    "        print(\"Json Value Error\")\n",
    "\n",
    "    return data, final_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f7701ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, PageTemplate, Frame\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.pagesizes import letter, landscape\n",
    "\n",
    "\n",
    "class PDFUtils:\n",
    "    \"\"\"\n",
    "    A utility class for generating PDF documents with various content.\n",
    "\n",
    "    Args:\n",
    "        pdf_file (str): The name of the PDF file to be generated.\n",
    "\n",
    "    Attributes:\n",
    "        pdf_template (SimpleDocTemplate): The PDF document template.\n",
    "        content (list): A list to store the content elements of the PDF.\n",
    "\n",
    "    Methods:\n",
    "        page_break(): Create a PageBreak element.\n",
    "        generate_page_title(title_name=\"Crime and Punishment Summary\"): Generate a title page for the PDF.\n",
    "        space_between_paragraph(width=1, height=12): Create a Spacer element to add space between paragraphs.\n",
    "        paragraph_style(name, font_size, alignment, space_after, fontName=\"Times-Roman\"): Define a custom ParagraphStyle.\n",
    "        generate_summary_pdf(data): Generate a PDF document containing summary content.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pdf_file=\"Book_summary\"):\n",
    "        \"\"\"\n",
    "               Initializes the PDF template and content list.\n",
    "\n",
    "               Args:\n",
    "                   pdf_file (str): The name of the PDF file to be generated.\n",
    "               \"\"\"\n",
    "        # Initialize pdf template\n",
    "        page_width, page_height = landscape(letter)\n",
    "        left_margin = 1.5 * 72\n",
    "        right_margin = 1.5 * 72\n",
    "        top_margin = 1 * 72\n",
    "        bottom_margin = 1.5 * 72\n",
    "        self.pdf_template = SimpleDocTemplate(pdf_file, pagesize=(page_width, page_height),\n",
    "                                              leftMargin=left_margin, rightMargin=right_margin,\n",
    "                                              topMargin=top_margin, bottomMargin=bottom_margin)\n",
    "        self.content = []\n",
    "\n",
    "    def page_break(self):\n",
    "        \"\"\"\n",
    "        Create a PageBreak element.\n",
    "\n",
    "       Returns:\n",
    "        PageBreak: A PageBreak element.\n",
    "       \"\"\"\n",
    "        return PageBreak()\n",
    "\n",
    "    def generate_page_title(self, title_name=\"Crime and Punishment Summary\"):\n",
    "        \"\"\"\n",
    "        Generate a title page for the PDF.\n",
    "\n",
    "        Args:\n",
    "            title_name (str): The title text for the page.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of content elements for the title page.\n",
    "        \"\"\"\n",
    "        title_page_style = getSampleStyleSheet()['Title']\n",
    "        title_page = Paragraph(title_name, title_page_style)\n",
    "        content = [self.space_between_paragraph(10, 100), title_page, self.page_break()]\n",
    "        return content\n",
    "\n",
    "    def space_between_paragraph(self, width=1, height=12):\n",
    "        \"\"\"\n",
    "        Create a Spacer element to add space between paragraphs.\n",
    "\n",
    "        Args:\n",
    "            width (int): The width of the spacer.\n",
    "            height (int): The height of the spacer.\n",
    "\n",
    "        Returns:\n",
    "            Spacer: A Spacer element.\n",
    "        \"\"\"\n",
    "        return Spacer(width, height)\n",
    "\n",
    "    def paragraph_style(self, name, font_size, alignment, space_after, fontName=\"Times-Roman\"):\n",
    "        \"\"\"\n",
    "        Define a custom ParagraphStyle.\n",
    "\n",
    "        Args:\n",
    "            name (str): The name of the ParagraphStyle.\n",
    "            font_size (int): The font size.\n",
    "            alignment (int): The text alignment (0=left, 1=center, 2=right).\n",
    "            space_after (int): The space after the paragraph.\n",
    "            fontName (str, optional): The font name. Defaults to \"Times-Roman\".\n",
    "\n",
    "        Returns:\n",
    "            ParagraphStyle: A custom ParagraphStyle.\n",
    "        \"\"\"\n",
    "        return ParagraphStyle(name=name, fontSize=font_size, alignment=alignment, spaceAfter=space_after,\n",
    "                              fontName=fontName)\n",
    "\n",
    "    def generate_summary_pdf(self, data):\n",
    "        \"\"\"\n",
    "        Generate a PDF document containing summary content.\n",
    "\n",
    "        Args:\n",
    "            data (dict): A dictionary containing the summary data organized by part number.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            chapter_style = self.paragraph_style(\"ChapterTitle\", 20, 1, 12)\n",
    "            paragraph_style = self.paragraph_style(\"CustomStyle\", 12, 4, 20)\n",
    "\n",
    "            page_title = self.generate_page_title()\n",
    "            self.content.extend(page_title)\n",
    "\n",
    "            for part_number, paragraphs in data.items():\n",
    "                chapter_title = Paragraph(part_number, chapter_style)\n",
    "                self.content.append(chapter_title)\n",
    "                self.content.append(self.space_between_paragraph(1, 12))\n",
    "                for paragraph in paragraphs:\n",
    "                    chapter_content = Paragraph(paragraph, paragraph_style)\n",
    "                    self.content.extend([chapter_content, self.space_between_paragraph(1, 12)])\n",
    "                    self.content.extend([self.space_between_paragraph(1, 12)])\n",
    "                self.content.append(self.page_break())\n",
    "            self.pdf_template.build(self.content)\n",
    "            print(\"Pdf successfully generated\")\n",
    "        except:\n",
    "            print(\"Pdf generation error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53d96ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver(pdf_path='crime-and-punishment.pdf'):\n",
    "    data_dict = []\n",
    "    pdf_summaries = []\n",
    "    # Step 1: Parse pdf\n",
    "    pdf_data = extract_pdf_data(pdf_path)\n",
    "    pdf_structure = create_pdf_structure(pdf_data)\n",
    "    \n",
    "    # Step 2: Generate summaries\n",
    "    pdf_summaries = generate_summaries(pdf_structure)\n",
    "    # Step 3: Transform the dictinary\n",
    "    if len(pdf_summaries):\n",
    "        data, data_dict = transform_json(pdf_summaries)\n",
    "    \n",
    "    # Step 4: Generate resultant pdf\n",
    "    pdf_object = PDFUtils(\"final_book_summary.pdf\")\n",
    "    if len(data_dict):\n",
    "        pdf_object.generate_summary_pdf(data_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7921c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing part: Part I and chapter number: Chapter I\n",
      "Processing part: Part I and chapter number: Chapter II\n",
      "Processing part: Part I and chapter number: Chapter III\n",
      "Processing part: Part I and chapter number: Chapter IV\n",
      "Processing part: Part I and chapter number: Chapter V\n",
      "Processing part: Part I and chapter number: Chapter VI\n",
      "Processing part: Part I and chapter number: Chapter VII\n",
      "Processing part: Part II and chapter number: Chapter I\n",
      "Processing part: Part II and chapter number: Chapter II\n",
      "Processing part: Part II and chapter number: Chapter III\n",
      "Processing part: Part II and chapter number: Chapter IV\n",
      "Processing part: Part II and chapter number: Chapter V\n",
      "Processing part: Part II and chapter number: Chapter VI\n",
      "Processing part: Part II and chapter number: Chapter VII\n",
      "Processing part: Part III and chapter number: Chapter I\n",
      "Processing part: Part III and chapter number: Chapter II\n",
      "Processing part: Part III and chapter number: Chapter III\n",
      "Processing part: Part III and chapter number: Chapter IV\n",
      "Processing part: Part III and chapter number: Chapter V\n",
      "Processing part: Part III and chapter number: Chapter VI\n",
      "Processing part: Part IV and chapter number: Chapter I\n",
      "Processing part: Part IV and chapter number: Chapter II\n",
      "Processing part: Part IV and chapter number: Chapter III\n",
      "Processing part: Part IV and chapter number: Chapter IV\n",
      "Processing part: Part IV and chapter number: Chapter V\n",
      "Processing part: Part IV and chapter number: Chapter VI\n",
      "Processing part: Part V and chapter number: Chapter I\n",
      "Processing part: Part V and chapter number: Chapter II\n",
      "Processing part: Part V and chapter number: Chapter III\n",
      "Processing part: Part V and chapter number: Chapter IV\n",
      "Processing part: Part V and chapter number: Chapter V\n",
      "Processing part: Part VI and chapter number: Chapter I\n",
      "Processing part: Part VI and chapter number: Chapter II\n",
      "Processing part: Part VI and chapter number: Chapter III\n",
      "Processing part: Part VI and chapter number: Chapter IV\n",
      "Processing part: Part VI and chapter number: Chapter V\n",
      "Processing part: Part VI and chapter number: Chapter VI\n",
      "Processing part: Part VI and chapter number: Chapter VII\n",
      "Processing part: Part VI and chapter number: Chapter VIII\n",
      "Pdf successfully generated\n"
     ]
    }
   ],
   "source": [
    "driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc4a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d02a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b806d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028625d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
